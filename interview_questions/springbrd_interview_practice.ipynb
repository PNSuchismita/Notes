{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Boot-Up\n",
    "\n",
    "### 1. What native data structures can you name in Python? Of these, which are mutable, and which are immutable?  \n",
    "\n",
    "* From Python3 documentation: https://docs.python.org/3/library/stdtypes.html   \n",
    "The principal built-in types are **numerics**, **sequences**, **mappings**, **classes**, **instances** and **exceptions**.  \n",
    "    * Numeric Types - **int, float, complex**\n",
    "        * **boolean** is a subtype of numeric type\n",
    "    * Iterator Types - Generator Types\n",
    "    * Sequence Types - **list, tuple, range**\n",
    "    * Text Sequence Type - **str**\n",
    "    * Binary Sequence Types — **bytes, bytearray, memoryview**\n",
    "    * Set Types — **set, frozenset**\n",
    "    * Mapping Types - **dict**\n",
    "    * Context Manager Types\n",
    "    * Other Built-in Types - **modules, classes and class instances, functions, methods, code objects, type objects, the null object, the ellipsis object, the notimplemented object, boolean values, internal objects**\n",
    "\n",
    "* From Wikipedia: https://en.wikibooks.org/wiki/Python_Programming/Data_Types\n",
    "\n",
    "| Some immutable types | Some mutable types \n",
    "| -------------------- | ------------------ \n",
    "| int, float, complex | array |\n",
    "| str | bytearray \n",
    "| bytes | list \n",
    "| tuple | set \n",
    "| frozenset | dict \n",
    "| bool |   \n",
    "\n",
    "\n",
    "### 2. Explain the difference between a list and a dictionary?\n",
    "\n",
    "From Quora: https://www.quora.com/What-is-the-difference-between-a-list-and-a-dictionary-in-Python\n",
    "* **List** is the most versatile mutable Sequence available in Python, which can be written as a list of comma-separated values between square brackets.\n",
    "    * Elements present in List maintain their order unless explicitly re-ordered .\n",
    "    * Elements are accessed through their numeric (zero based) index values.\n",
    "    * If you have a collection of data that does not need random access, use List.\n",
    "    * Where you have to deal with values which can be changed, use List.\n",
    "* **Dictionary** is an unordered mutable collection of key-value pairs. Dictionaries are used to handle large amount of data.\n",
    "    * Every entry is a key-value pair.\n",
    "    * Elements are accessed using key values.\n",
    "    * When you are dealing with unique keys and you are mapping values to the keys, use Dictionary.\n",
    "                   \n",
    "### 3. In a list, what data types can be elements?\n",
    "\n",
    "* The elements present in list can be of any type (float, string, tuple, list, etc.), and types can be mixed.\n",
    "       \n",
    "### 4. In a dictionary, what data types can the key be? And the values? Why?\n",
    "    \n",
    "* Key values can be of any hashable type (i.e. not a dict), which includes: strings, numbers, and tuples. Types can be mixed.\n",
    "    * For example, lists can't be keys because they are not hashable and looking up different lists with the same contents would produce different results, even though comparing lists with the same contents would indicate them as equivalent.\n",
    "* Values can be of any type (including other dict’s), and types can be mixed.\n",
    "    \n",
    "    \n",
    "### 5. When would you use a list vs. a tuple vs. a set in Python?\n",
    "\n",
    "* Use **sets** if you have hashable items, don't care either way about order or duplicates, and want speedy membership checking.\n",
    "* Use **lists** when you have non-hashable items, care about the order or duplicates, and want to change the items (mutate).\n",
    "* Use **tuples** if you're defining a constant set of values (don't need to change the values later) and all you're ever going to do with it is iterate through it (tuples are faster than lists).\n",
    "    \n",
    "    \n",
    "### 6. Explain the difference between a for loop and a while loop.\n",
    "\n",
    "* **While** loop is used in situations where we do not know how many times loop needs to be excuted beforehand.\n",
    "    * In while loop, condition is checked first, if the given condition is true, then the control will enter the body of the loop.\n",
    "* **For** loop is used where we already know about the number of times loop needs to be excuted. Typically for a index used in iteration.\n",
    "    * In the For loop you MUST create a new variable, thats not true for the While loop.\n",
    "\n",
    "\n",
    "### 7. What packages in the standard library, useful for Data Science work, do you know?\n",
    "\n",
    "* In standard library. From Python3 documentation: https://docs.python.org/3/library/index.html\n",
    "\n",
    "    1. **re — Regular expression operations**. This module provides regular expression matching operations.\n",
    "        * re.split(pattern, string, maxsplit=0, flags=0), re.sub(pattern, repl, string, count=0, flags=0), re.findall(pattern, string, flags=0), etc.\n",
    "    2. **math — Mathematical functions**. This module is always available. It provides access to the mathematical functions defined by the C standard.\n",
    "        * math.ceil(x), math.floor(x), math.factorial(x), math.isnan(x), math.remainder(x, y), math.exp(x), math.expm1(x) - Return e raised to the power x, minus 1, math.log(x[, base]), math.log1p(x) - Return the natural logarithm of 1+x (base e), math.log2(x) - Return the base-2 logarithm of x, math.log10(x) - Return the base-10 logarithm of x, math.pow(x, y), math.sqrt(x), math.pi, math.e, math.nan, math.inf, etc.\n",
    "    3. **random — Generate pseudo-random**. This module implements pseudo-random number generators for various distributions.\n",
    "        * random.seed(a=None, version=2), random.randint(a, b), random.choice(seq), random.shuffle(x[, random]), random.sample(population, k), random.random() - Return the next random floating point number in the range [0.0, 1.0)., random.uniform(a, b), random.normalvariate(mu, sigma), etc.\n",
    "    4. **datetime — Basic date and time types**. The datetime module supplies classes for manipulating dates and times in both simple and complex ways.\n",
    "        * **Available Types**. class datetime.date, class datetime.time, class datetime.datetime, class datetime.timedelta, class datetime.tzinfo, class datetime.timezone\n",
    "        * **timedelta Objects**. A timedelta object represents a duration, the difference between two dates or times.\n",
    "            * class datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
    "            * timedelta.min, timedelta.max, timedelta.total_seconds(), mathematical operations with timedeltas, etc..\n",
    "        * **date Objects**. A date object represents a date (year, month and day) in an idealized calendar, the current Gregorian calendar indefinitely extended in both directions.\n",
    "            * class datetime.date(year, month, day)\n",
    "            * date.min, date.max, date.year, date.month, date.day, date.replace(year=self.year, month=self.month, day=self.day), date.weekday(), date.strftime(format), etc.\n",
    "        * **datetime Objects**. A datetime object is a single object containing all the information from a date object and a time object.\n",
    "            * class datetime.datetime(year, month, day, hour=0, minute=0, second=0, microsecond=0, tzinfo=None, *, fold=0)\n",
    "            * classmethod datetime.today(), classmethod datetime.now(tz=None), classmethod datetime.strptime(date_string, format), datetime.year, datetime.month, datetime.day, datetime.hour, datetime.minute, datetime.second, datetime.microsecond, datetime.weekday(), etc.\n",
    "    5. **os.path — Common pathname manipulations**. This module implements some useful functions on pathnames.\n",
    "        * os.path.exists(path), os.path.isfile(path), os.path.isdir(path), os.path.islink(path), os.path.join(path, *paths), os.path.samefile(path1, path2), os.path.split(path), etc.\n",
    "    6. **glob — Unix style pathname pattern expansion**. The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, although results are returned in arbitrary order.\n",
    "        * glob.glob(pathname, *, recursive=False), glob.iglob(pathname, *, recursive=False), glob.escape(pathname) - Escape all special characters ('?', '*' and '[')\n",
    "    7. **statistics — Mathematical statistics functions**. This module provides functions for calculating mathematical statistics of numeric (Real-valued) data.\n",
    "        * These functions calculate an average ortypical value from a population or sample.\n",
    "\n",
    "| | \n",
    "|------- | -----------------------------------\n",
    "| mean() | Arithmetic mean (“average”) of data.\n",
    "| harmonic_mean() | Harmonic mean of data.\n",
    "| median() | Median (middle value) of data.\n",
    "| median_low() | Low median of data.\n",
    "| median_high() | High median of data.\n",
    "| median_grouped() | Median, or 50th percentile, of grouped data.\n",
    "| mode() | Mode (most common value) of discrete data.\n",
    "\n",
    "| These functions calculate a measure of how much the population or|sample tends to deviate from the typical or average values.\n",
    "|-|------------------------------------------------\n",
    "| pstdev() | Population standard deviation of data.\n",
    "| pvariance() | Population variance of data.\n",
    "| stdev() | Sample standard deviation of data.\n",
    "| variance()| Sample variance of data.\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "* Not in standard library. From https://www.upwork.com/hiring/data/15-python-libraries-data-science/\n",
    "    1. **NumPy** is the foundational library for scientific computing in Python. NumPy introduces objects for multidimensional arrays and matrices, as well as routines that allow developers to perform advanced mathematical and statistical functions on those arrays with as little code as possible.\n",
    "    2. **SciPy** builds on NumPy by adding a collection of algorithms and high-level commands for manipulating and visualizing data. This package includes functions for computing integrals numerically, solving differential equations, optimization, and more.\n",
    "    3. **Pandas** adds data structures and tools that are designed for practical data analysis in finance, statistics, social sciences, and engineering. Pandas works well with incomplete, messy, and unlabeled data (i.e., the kind of data you’re likely to encounter in the real world), and provides tools for shaping, merging, reshaping, and slicing datasets.\n",
    "    4. **matplotlib** is the standard Python library for creating 2D plots and graphs. It’s pretty low-level, meaning it requires more commands to generate nice-looking graphs and figures than with some more advanced libraries. However, the flip side of that is flexibility. With enough commands, you can make just about any kind of graph you want with matplotlib.\n",
    "    5. **scikit-learn** builds on NumPy and SciPy by adding a set of algorithms for common machine learning and data mining tasks, including clustering, regression, and classification. As a library, scikit-learn has a lot going for it. Its tools are well-documented and its contributors include many machine learning experts. What’s more, it’s a very curated library, meaning developers won’t have to choose between different versions of the same algorithm. Its power and ease of use make it popular with a lot of data-heavy startups, including Evernote, OKCupid, Spotify, and Birchbox.\n",
    "    6. **TensorFlow** is another high-profile entrant into machine learning, developed by Google as an open-source successor to DistBelief, their previous framework for training neural networks. TensorFlow uses a system of multi-layered nodes that allow you to quickly set up, train, and deploy artificial neural networks with large datasets. It’s what allows Google to identify objects in photos or understand spoken words in its voice-recognition app.\n",
    "    7. **Seaborn** is a popular visualization library that builds on matplotlib’s foundation. The first thing you’ll notice about Seaborn is that its default styles are much more sophisticated than matplotlib’s. Beyond that, Seaborn is a higher-level library, meaning it’s easier to generate certain kinds of plots, including heat maps, time series, and violin plots.\n",
    "\n",
    "\n",
    "### 8. Do you know any additional data structures available in the standard library?\n",
    "\n",
    "From Python3 documentation: https://docs.python.org/3/library/index.html\n",
    "\n",
    "* Available types from datetime modul\n",
    "    * class **datetime.date**\n",
    "    * class **datetime.time**\n",
    "    * class **datetime.datetime**\n",
    "    * class **datetime.timedelta**\n",
    "    * class **datetime.tzinfo**\n",
    "    * class **datetime.timezone**\n",
    "* **collections — Container datatypes**. This module implements specialized container datatypes providing alternatives to Python’s general purpose built-in containers, dict, list, set, and tuple.\n",
    "\n",
    "|   | \n",
    "| - |\n",
    "| namedtuple() | factory function for creating tuple subclasses with named fields\n",
    "| deque | list-like container with fast appends and pops on either end\n",
    "| ChainMap | dict-like class for creating a single view of multiple mappings\n",
    "| Counter | dict subclass for counting hashable objects\n",
    "| OrderedDict | dict subclass that remembers the order entries were added\n",
    "| defaultdict | dict subclass that calls a factory function to supply missing values\n",
    "| UserDict | wrapper around dictionary objects for easier dict subclassing\n",
    "| UserList | wrapper around list objects for easier list subclassing\n",
    "| UserString | wrapper around string objects for easier string subclassing\n",
    "    \n",
    "* **array — Efficient arrays of numeric values**. This module defines an object type which can compactly represent an array of basic values: characters, integers, floating point numbers. Arrays are sequence types and behave very much like lists, except that the type of objects stored in them is constrained. The type is specified at object creation time by using a type code, which is a single character. The type codes can be found in the documentation.\n",
    "    * class array.array(typecode[, initializer])\n",
    "        * array.append(x), array.count(x), array.extend(iterable), array.index(x), array.insert(i, x), array.pop([i]), array.remove(x), array.tobytes(), array.tofile(f), array.tolist(), array.tostring(), array.tounicode(), etc.\n",
    "\n",
    "### 9. Can you explain what a list or dict comprehension is?\n",
    "\n",
    "Comprehensions are simply one line for loops that result in the building of a list, dict, set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "## Pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What data structures does pandas introduce which aren’t native to Python?\n",
    "\n",
    "From pandas documentation: https://pandas.pydata.org/pandas-docs/stable/dsintro.html\n",
    "\n",
    "### *Series*  \n",
    "\n",
    "Series is a one-dimensional labeled array capable of holding any data type (integers, strings, floating point numbers, Python objects, etc.). The axis labels are collectively referred to as the **index**.   \n",
    "\n",
    "Can be created from \n",
    "* **ndarray**, \n",
    "* **Python dict**,\n",
    "* **scalar value (like 5)**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a   -0.204048\n",
       "b    0.317970\n",
       "c   -1.925335\n",
       "d   -0.955108\n",
       "e    1.317976\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###############    From ndarray    ####################\n",
    "### index must be the same length as data. \n",
    "### If no index is passed, one will be created having values [0, ..., len(data) - 1].\n",
    "s = pd.Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0.0\n",
      "b    1.0\n",
      "c    2.0\n",
      "dtype: float64 \n",
      "\n",
      "b    1.0\n",
      "c    2.0\n",
      "d    NaN\n",
      "a    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "###############     From dict      #####################\n",
    "### When the data is a dict, and an index is not passed, \n",
    "### the Series index will be ordered by the dict’s insertion order, \n",
    "### if you’re using Python version >= 3.6 and Pandas version >= 0.23.\n",
    "d = {'a' : 0., 'b' : 1., 'c' : 2.}\n",
    "print(pd.Series(d), '\\n')\n",
    "\n",
    "### If an index is passed, the values in data corresponding to the labels in the index will be pulled out\n",
    "print(pd.Series(d, index=['b', 'c', 'd', 'a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    5.0\n",
       "b    5.0\n",
       "c    5.0\n",
       "d    5.0\n",
       "e    5.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################    From scalar value     ##################\n",
    "### If data is a scalar value, an index must be provided. \n",
    "### The value will be repeated to match the length of index.\n",
    "pd.Series(5., index=['a', 'b', 'c', 'd', 'e'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *DataFrame*\n",
    "\n",
    "DataFrame is a 2-dimensional labeled data structure with columns of potentially different types. You can think of it like a spreadsheet or SQL table, or a dict of Series objects. It is generally the most commonly used pandas object.   \n",
    "\n",
    "Like Series, DataFrame accepts many different kinds of input:  \n",
    "\n",
    "* **Dict of 1D ndarrays, lists, dicts, or Series**\n",
    "* **2-D numpy.ndarray**\n",
    "* **Structured or record ndarray**\n",
    "* **A Series** . The result will be a DataFrame with the same index as the input Series, and with one column whose name is the original name of the Series (only if no other column name provided).\n",
    "* **Another DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "0  1.0  4.0\n",
      "1  2.0  3.0\n",
      "2  3.0  2.0\n",
      "3  4.0  1.0 \n",
      "\n",
      "   one  two\n",
      "a  1.0  4.0\n",
      "b  2.0  3.0\n",
      "c  3.0  2.0\n",
      "d  4.0  1.0\n"
     ]
    }
   ],
   "source": [
    "##############     From dict of ndarrays / lists     #################\n",
    "d = {'one' : [1., 2., 3., 4.], \n",
    "     'two' : [4., 3., 2., 1.]}\n",
    "print(pd.DataFrame(d), '\\n')\n",
    "print(pd.DataFrame(d, index=['a', 'b', 'c', 'd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   one  two\n",
      "a  1.0  1.0\n",
      "b  2.0  2.0\n",
      "c  3.0  3.0\n",
      "d  NaN  4.0 \n",
      "\n",
      "   one  two\n",
      "d  NaN  4.0\n",
      "b  2.0  2.0\n",
      "a  1.0  1.0 \n",
      "\n",
      "   two three\n",
      "d  4.0   NaN\n",
      "b  2.0   NaN\n",
      "a  1.0   NaN\n"
     ]
    }
   ],
   "source": [
    "##############     From dict of Series or dicts      #################\n",
    "d = {'one' : pd.Series([1., 2., 3.], index=['a', 'b', 'c']),\n",
    "     'two' : pd.Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "print(pd.DataFrame(d), '\\n')\n",
    "print(pd.DataFrame(d, index=['d', 'b', 'a']), '\\n')\n",
    "print(pd.DataFrame(d, index=['d', 'b', 'a'], columns=['two', 'three']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A    B         C\n",
      "0  1  2.0  b'Hello'\n",
      "1  2  3.0  b'World' \n",
      "\n",
      "        A    B         C\n",
      "first   1  2.0  b'Hello'\n",
      "second  2  3.0  b'World' \n",
      "\n",
      "          C  A    B\n",
      "0  b'Hello'  1  2.0\n",
      "1  b'World'  2  3.0\n"
     ]
    }
   ],
   "source": [
    "#############   From structured or record array    #####################\n",
    "\n",
    "## This case is handled identically to a dict of arrays.\n",
    "data = np.zeros((2,), dtype=[('A', 'i4'),('B', 'f4'),('C', 'a10')])\n",
    "data[:] = [(1,2.,'Hello'), (2,3.,\"World\")]\n",
    "\n",
    "print(pd.DataFrame(data), '\\n')\n",
    "print(pd.DataFrame(data, index=['first', 'second']), '\\n')\n",
    "print(pd.DataFrame(data, columns=['C', 'A', 'B']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b     c\n",
       "0  1   2   NaN\n",
       "1  5  10  20.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############       From a list of dicts       #################\n",
    "data2 = [{'a': 1, 'b': 2}, {'a': 5, 'b': 10, 'c': 20}]\n",
    "pd.DataFrame(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">a</th>\n",
       "      <th colspan=\"2\" halign=\"left\">b</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">A</th>\n",
       "      <th>B</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       a              b      \n",
       "       a    b    c    a     b\n",
       "A B  4.0  1.0  5.0  8.0  10.0\n",
       "  C  3.0  2.0  6.0  7.0   NaN\n",
       "  D  NaN  NaN  NaN  NaN   9.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############      From a dict of tuples        ##################\n",
    "pd.DataFrame({('a', 'b'): {('A', 'B'): 1, ('A', 'C'): 2},\n",
    "              ('a', 'a'): {('A', 'C'): 3, ('A', 'B'): 4},\n",
    "              ('a', 'c'): {('A', 'B'): 5, ('A', 'C'): 6},\n",
    "              ('b', 'a'): {('A', 'C'): 7, ('A', 'B'): 8},\n",
    "              ('b', 'b'): {('A', 'D'): 9, ('A', 'B'): 10}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How can you deal with missing values?\n",
    "\n",
    "From DataCamp's Cleaning Data in Python course: https://campus.datacamp.com/courses/cleaning-data-in-python/cleaning-data-for-analysis?ex=11\n",
    "\n",
    "* Leave as-is\n",
    "* **Drop** using **.dropna()** method on our data frame. If a row or column contains all missing values, we can safely drop that row or column.\n",
    "* **Fill in ** using **.fillna()** method on our data frame. We can fill in with a provided value or some summary statistic, for example, median if we have outliers, mean if we don't have outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What is the difference between the .loc and the .iloc indexers?\n",
    "\n",
    "From pandas documentation: https://pandas.pydata.org/pandas-docs/stable/indexing.html\n",
    "\n",
    "* **.loc** is primarily label based, but may also be used with a boolean array. .loc will raise KeyError when the items are not found. Allowed inputs are:\n",
    "\n",
    "    * A single label, e.g. 5 or 'a' (Note that 5 is interpreted as a label of the index. This use is not an integer position along the index.).\n",
    "    * A list or array of labels ['a', 'b', 'c'].\n",
    "    * A slice object with labels 'a':'f' (Note that contrary to usual python slices, both the start and the stop are included, when present in the index! See Slicing with labels.).\n",
    "    * A boolean array\n",
    "    * A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above).\n",
    "\n",
    "* **.iloc** is primarily integer position based (from 0 to length-1 of the axis), but may also be used with a boolean array. .iloc will raise IndexError if a requested indexer is out-of-bounds, except slice indexers which allow out-of-bounds indexing. (this conforms with Python/NumPy slice semantics). Allowed inputs are:\n",
    "    * An integer e.g. 5.\n",
    "    * A list or array of integers [4, 3, 0].\n",
    "    * A slice object with ints 1:7.\n",
    "    * A boolean array.\n",
    "    * A callable function with one argument (the calling Series, DataFrame or Panel) and that returns valid output for indexing (one of the above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What file formats for storing data do you know?\n",
    "\n",
    "From Analytics Vidhya's article \"How to read most commonly used file formats in Data Science (using Python)?\": https://www.analyticsvidhya.com/blog/2017/03/read-commonly-used-formats-using-python/\n",
    "\n",
    "* **CSV, xls, xlsx**: Comma Separated Values (CSV), Microsoft Excel Spreadsheet (xls) and Microsoft Excel Open XML Spreadsheet (xlsx) - data is stored in cells, each cell is organized in rows and columns. \n",
    "* **.zip**: ZIP files (.zip), an archive file format. An archive file format is used to collect multiple data files together into a single file (along with metadata) to use less storage space.\n",
    "* **text**: Plain Text (txt) file format. Usually, this text is in unstructured form and there is no meta-data associated with it.\n",
    "* **JSON** file format: JavaScript Object Notation(JSON) is a text-based open standard designed for exchanging the data over web. JSON format is used for transmitting structured data over the web.\n",
    "* **XML** file format. XML is also known as Extensible Markup Language. As the name suggests, it is a markup language. It has certain rules for encoding data. XML file format is a human-readable and machine-readable file format.\n",
    "* **HTML** files. HTML stands for Hyper Text Markup Language. It is the standard markup language which is used for creating Web pages. HTML is used to describe structure of web pages using markup. HTML tags are same as XML but these are predefined.\n",
    "* **Image** files. For example .png. Usual image files are 3-Dimensional, having RGB values. But, they can also be 2-Dimensional (grayscale) or 4-Dimensional (having intensity) – an Image consisting of pixels and meta-data associated with it.\n",
    "* ...\n",
    "\n",
    "### 5. What is the standard way of marking missing values in pandas?\n",
    "\n",
    "**NaN** is the default missing value marker in pandas.\n",
    "\n",
    "### 6. What features of pandas do you like particularly? Any that you dislike?\n",
    "\n",
    "Some of the features that I use a lot and like very much:\n",
    "\n",
    "* Groupby + Aggregate/Transform to create new columns\n",
    "* .rolling() to compute rolling average, volatility, etc.\n",
    "* ...\n",
    "\n",
    "Not that I dislike it, but I have come to realise that I don't like using merge feature of pandas especially when I have a large data set.\n",
    "\n",
    "\n",
    "### 7. What kind of indexes exist in pandas DataFrames?\n",
    "\n",
    "The index of a DataFrame is a set that consists of a label for each row.\n",
    "\n",
    "* **Int64Index** _ Immutable array implementing an ordered, sliceable set. Prior to 0.18.0, the default index for all NDFrame objects.\n",
    "* **RangeIndex** _ consists of integers, a sub-class of Int64Index added in version 0.18.0, now providing the default index for all NDFrame objects.\n",
    "* **Float64Index** - By default a Float64Index will be automatically created when passing floating, or mixed-integer-floating values in index creation. This enables a pure label-based slicing paradigm that makes [],ix,loc for scalar indexing and slicing work exactly the same.\n",
    "* **IntervalIndex** - IntervalIndex together with its own dtype, interval as well as the Interval scalar type, allow first-class support in pandas for interval notation. The IntervalIndex allows some unique indexing and is also used as a return type for the categories in cut() and qcut().\n",
    "* **DateTimeIndex** _ list of Timestamp\n",
    "* **PeriodIndex** _ list of Period\n",
    "* **MultiIndex** _ has multiple levels\n",
    "* **CategoricalIndex** - CategoricalIndex is a type of index that is useful for supporting indexing with duplicates. This is a container around a Categorical and allows efficient indexing and storage of an index with a large number of duplicated elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL\n",
    "\n",
    "I have the answers to these and other SQL questions in my other notebook, \"109 Commonly Asked Data Science Interview Questions\": https://github.com/arstepanyan/Notes/blob/master/interview_questions/109_interview_questions.ipynb\n",
    "\n",
    "### 1. What are aggregations in SQL?\n",
    "\n",
    "Group functions (also called aggregate functions) are mathematical functions to operate on sets of rows to give one result per set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Can you explain the different types of SQL JOINs?\n",
    "\n",
    "* **Inner joins** eliminate rows from the tables that do not satisfy the join condition set forth in the ON statement. When performing an inner join, rows from either table that are unmatched in the other table are not returned.\n",
    "    * In mathematical terms, an inner join is the **intersection** of the two tables.\n",
    "* In an **outer join**, unmatched rows in one or both tables can be returned. There are a few types of outer joins:\n",
    "    * **LEFT JOIN** returns only unmatched rows from the left table.\n",
    "    * **RIGHT JOIN** returns only unmatched rows from the right table.\n",
    "    * **FULL OUTER JOIN** returns unmatched rows from both tables.\n",
    "* **UNION** allows you to stack one dataset on top of the other, while SQL joins allow you to combine two datasets side-by-side. Put differently, **UNION** allows you to write two separate SELECT statements, and to have the results of one statement display in the same table as the results from the other statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Give an example of some aggregation functions in SQL.\n",
    "\n",
    "The types of group functions are:\n",
    " \n",
    "* **AVG**, that calculates the average of the specified columns in a set of rows,\n",
    "* **COUNT**, calculating the number of rows in a set.\n",
    "* **MAX**, calculating the maximum,\n",
    "* **MIN**, calculating the minimum,\n",
    "* **STDDEV**, calculating the standard deviation,\n",
    "* **SUM**, calculating the sum,\n",
    "* **VARIANCE**, calculating the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Can you explain the difference between the WHERE and HAVING filters?\n",
    "\n",
    "The above aggregate functions are usually used with **GROUP BY** clause. You can farther use **HAVING** clause to filter out rows from the groups. Do not confuse it with **WHERE** clause.\n",
    "\n",
    "* **GROUP BY** allows you to separate data into groups, which can be aggregated independently of one another.\n",
    "* **HAVING** clause filters rows AFTER the GROUPING action (i.e., after the calculation of the aggregate functions).\n",
    "* **WHERE** clause is used to filter rows BEFORE the GROUPING action (i.e., before the calculation of the aggregate functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
