{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Modeling and Management Systems\n",
    "\n",
    "[Big Data Specialization, UC San Diego, Coursera](https://www.coursera.org/specializations/big-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "* **The Goal of  Data Modeling**. Formally explore the nature of data, so that you can figure out what kind of storage you need, and what kind of processing you can do on it.\n",
    "\n",
    "* **The Goal of Data Management**. Figure out what kind of infrastructure support you would need for the data. For example\n",
    "    * Does your environment need to keep multiple replicas of the data? \n",
    "    * Do you need to do statistical computation with the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "\n",
    "Ingestion means the process of getting the data into the data system that we are building or using.\n",
    "\n",
    "Questions to ask when you automate the data ingestion.\n",
    "\n",
    "* **How many** data **sources**?\n",
    "* **How large** are data **items**?\n",
    "* Will the number of **data sources grow**?\n",
    "* **Rate** of data ingestion?\n",
    "* What to do with **bad data**?\n",
    "* What to do when data is **too little or too much**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storage\n",
    "\n",
    "* How much data to store?\n",
    "    * **Capacity**\n",
    "        * What should be the size of the memory?\n",
    "        * How large and how many disk units should we have, and so forth.\n",
    "    * **Scalability**\n",
    "        * Should the storage devices be attached directly to the computers to make the direct IO fast but less scalable?\n",
    "        * Or should the storage be attached to the network that connect the computers in the cluster?  \n",
    "            This will make disk access a bit slower but allows one to add more storage to the system easily.\n",
    "* How fast do we need to read/write?\n",
    "    * **Cache memory**: lives inside the CPU and is very fast.\n",
    "    * **SSD**s (Solid State Device) are faster than **HDD** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality\n",
    "\n",
    "* Better quality means better analytics and better decision making.\n",
    "* Quality assurance means needed for regulatory compliance.\n",
    "* Quality leads to better engagement and interaction with external entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Operations\n",
    "\n",
    "* Operations **on single data items** that produce a sub-item\n",
    "* Operations **on collections of data items**\n",
    "    * Operations that **select** a part of a collection\n",
    "    * Operations that **combine** two collections\n",
    "    * Operations that **compute a function** on a collection\n",
    "* Efficiency of Data Operations\n",
    "    * Measured by time and space\n",
    "    * Should use parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scalability and Security\n",
    "\n",
    "* Scalability\n",
    "    * **Scaling Up** (Vertical Scaling): Making a server more poweful\n",
    "        * Adding more processors and RAM, buying more expensive and robust server\n",
    "        * Many **operations perform better** with more memory, more cores\n",
    "        * Maintenance can be difficult, expensive\n",
    "    * **Scaling Out** (Horizontal Scaling): Adding more machines\n",
    "        * Adding more, possibly less poweful machines that interconnect over a network\n",
    "        * **Parallel operations** will possibly be **slower**\n",
    "        * Easier in practice to add more machines\n",
    "* Data Security\n",
    "    * A must for sensitive data\n",
    "    * Increasing the number of machines leads to more security risks\n",
    "    * Data in transit must be secure\n",
    "    * Encryption and decryption increase security but make data operations expensive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Management Application: Flight Data Management at FlightStats\n",
    "\n",
    "* http://www.flightstats.com\n",
    "* Data for your apps: https://developer.flightstats.com\n",
    "* The Hub (open source): https://github.com/flightstats/hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Model\n",
    "\n",
    "The components of a Data Model are Structures, Operations, and Constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structures\n",
    "\n",
    "* **Structured Data**: Repeatable Pattern of Organization.\n",
    "* **Unstructures Data**: Just looking at it, it's impossible to figure out how the data is organized and how to identify subparts of the data.\n",
    "    * .jpg, .mp4, encrypted data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations\n",
    "\n",
    "Operations specify the methods to manipulate the data.    \n",
    "Types of operations that are usually performed across all data models.  \n",
    "\n",
    "* **\"Subsetting\"**: Find a subset of data from the collection so that each element in the subset satisfies a specified condition. \n",
    "    * Depending of the context, it is also called **Selection** or **Filtering**\n",
    "* **\"Substructure extraction\"**: Given a data collections with some structure, extract from each data item a part of the structure as specified by a condition.\n",
    "    * **Projection**\n",
    "* **\"Union\"**: Given two data collections, create a new one with elements of the two input collections.\n",
    "    * **The assumption** behind the union operation is that the two collections involved have the **same structure**. In other words, if one collection has four fields and another has 14 fields, or if one has four fields on people and the dates of birth, and the other has four fields about countries and their capitols, they cannot be combined through union.\n",
    "    * **Set Union**: When duplicates are not allowed\n",
    "* **\"Join\"**: Given two data collections, create a new one with elements of the two input collections. \n",
    "    * In this kind of data combination there are two stages. **First**, for each data item of collection one, one finds a set of matching data items in collection two. In the **second** phase of the operation, all fields of the matching record pairs are put together.\n",
    "    * Complex and can be very expensive when the size of the collections are large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints\n",
    "\n",
    "* Value constraint\n",
    "    * Age is never negative\n",
    "* Uniqueness constraint\n",
    "    * A movie can have only one title\n",
    "* Cardinality constraint\n",
    "    * A person can take between 0 and 3 blood pressure medications at a time.\n",
    "* Type constraint\n",
    "    * Last Name is alphabetical\n",
    "* Domain constraint\n",
    "    * Day in (1, ..., 31), Month in (1, ..., 12) or ('Jan', ... 'Dec')\n",
    "    \n",
    "**Structural Constraints**: A structural constraint puts restrictions on the structure of the data rather than the data values themselves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Data Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Data Model\n",
    "\n",
    "One of the simplest and most frequent data models. MySQL, Oracle, Teradata, and so forth. The primary data structure for a relational model is a **table**.  \n",
    "\n",
    "* The table actually represents a set of tuples, a collection of distinct elements of the same type.\n",
    "* A row (a record) is a relational tuple and, unless otherwise stated, the elements of a relational tuple are **atomic**. That is, they represent one unit of information and cannot be decomposed further.\n",
    "* **Relational Schema**: The first row of a table is a part of the schema. It tells us\n",
    "    * the **name of the table**,\n",
    "    * **names of the columns**,\n",
    "    * for each column, the **allowed data type**.\n",
    "    * It can also specify **constraints** on the fields/columns.\n",
    "    * Additionally, it tells what column is the **Primary key**.\n",
    "* **Primary Key**: Unique to each record\n",
    "* **Foreign Key**: A key that refers to the primary key in another table. It is not the primary key of the table it belongs to because it can be repeated, for example, to represent a piece of information at different times.\n",
    "    * Salaries of employees at different times => employee id (foreign key) will be repeated. But it will map to the main table of employees where the employee id will be the primary key.\n",
    "    * **Natural Join**: When we do a join of this type of a table with the main employee table, there will be several rows with the same employee id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semistructure Data Model\n",
    "\n",
    "* **HTML**: Everywhere a block is nested within a larger block.\n",
    "* **XML** (extensible markup language): A generalization of HTML where the elements, that's the beginning and end markers within the angular brackets, can be any string. And not like the ones allowed by standard HTML.\n",
    "* **JSON** (JavaScript Object Notation): Key-Value pairs. Popular format used for many different data like Twitter and Facebook. \n",
    "\n",
    "One way to generalize all these different forms of semi structured data is to **model them as trees**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Space Model\n",
    "\n",
    "* **Document Vector**. Example: 3 documents, *d1: \"new york times\"*, *d2: \"new york post\"*, *d3: \"los angeles times\"*.\n",
    "    * Let's create the **Term frequency (TF)** matrix  \n",
    "|    | angeles | los | new | post | times | york |\n",
    "| -- | ------- | --- | --- | ---- | ----- | ---- |\n",
    "| d1 | 0 | 0 | 1 | 0 | 1 | 1 |\n",
    "| d2 | 0 | 0 | 1 | 1 | 0 | 1 |\n",
    "| d3 | 1 | 1 | 0 | 0 | 1 | 0 |\n",
    "    * **Inverse document frequency** (IDF)  \n",
    "    The **document frequency** of a term is the count of that term in the whole collection divided by the number of documents. Here, we take the **inverse** of the document frequency, so that n, the number of documents, is in the numerator. IDF acts like a **penalty factor for terms** which are too **widely used** to be considered informative.  \n",
    "| Term | Doc-Frequency | IDF |\n",
    "| ------- | ------------- | --- |\n",
    "| angeles | 1 | $log_{2}{3 \\text{/} 1}$ = 1.584 |\n",
    "| los     | 1 | $log_{2}{3 \\text{/} 1}$ = 1.584 |\n",
    "| new     | 2 | $log_{2}{3 \\text{/} 2}$ = 0.584 |\n",
    "| post    | 1 | $log_{2}{3 \\text{/} 1}$ = 1.584 | \n",
    "| times   | 2 | $log_{2}{3 \\text{/} 2}$ = 0.584 |\n",
    "| york    | 2 | $log_{2}{3 \\text{/} 2}$ = 0.584 |\n",
    "    * **tf-idf** matrix (tf x idf)  \n",
    "    For each document, we have a vector represented here as a row. So that row represents the relative importance of each term in the vocabulary.  \n",
    "|    | angeles | los | new | post | times | york | Length        |\n",
    "| -- | ------- | --- | --- | ---- | ----- | ---- | ------------- |\n",
    "| d1 | 0 | 0 | 0.584 | 0 | 0.584 | 0.584 | $\\sqrt{0.584^2 + 0.584^2 + 0.584^2}$ = 1.011 |\n",
    "| d2 | 0 | 0 | 0.584 | 1.584 | 0 | 0.584 | $\\sqrt{0.584^2 + 1.584^2 + 0.584^2}$ = 1.786 |\n",
    "| d3 | 1.584 | 1.584 | 0 | 0 | 0.584 | 0 | $\\sqrt{1.584^2 + 1.584^2 + 0.584^2}$ = 2.316 |\n",
    "\n",
    "* Searching in Vector Space\n",
    "    * query = \"new new york\"\n",
    "    * Max frequency of a term (\"new\") = 2\n",
    "    * Create the query vector   \n",
    "|    | angeles | los | new | post | times | york | Length        |\n",
    "| -- | ------- | --- | --- | ---- | ----- | ---- | ------------- |\n",
    "| q | 0 | 0 | (2/2)*0.584=0.584 | 0 | 0 | (1/2)*0.584=0.292 | $\\sqrt{0.584^2 + 0.292^2}$ = 0.652 |\n",
    "    * A similarity function between two vectors is a measure of how far they are apart\n",
    "        * **Cosine distance**: If the vectors are identical, then the angle between them is zero. And therefore, the cosine function evaluates to one. As the angle increases, the value of the cosine function decreases to make them more dissimilar.  \n",
    "\\begin{equation*}\n",
    "similarity = cos(Q) = \\frac{A * B}{ \\Vert A  \\Vert  \\Vert B  \\Vert} = \\frac{\\sum_{i=1}^{n}A_iB_i}{\\sqrt{\\sum_{i=1}^{n}A_i^2} \\sqrt{\\sum_{i=1}^{n}B_i^2}}\n",
    "\\end{equation*}\n",
    "cosSim(d1, q) = (0.584 * 0.584 + 0.584 * 0.292) / (1.011 * 0.652) = 0.776   \n",
    "cosSim(d2, q) = (0.584 * 0.584) / (1.786 * 0.652) = 0.292  \n",
    "cosSim(d3, q) = (0.584 * 0.292) / (2.316 * 0.652) = 0.112\n",
    "    \n",
    "    * Every query term may optionally be associated with a weighting term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading\n",
    "\n",
    "[Getting started with storage. Understanding SAN vs NAS vs DAS.](https://vanillavideo.com/blog/2014/started-storage-understanding-san-nas-das)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
